# -*- coding: utf-8 -*-
import scrapy
import re
import time
from tutorial.items import BookItem, BookChapterItem
from scrapy.http import Request


class DmozSpider(scrapy.Spider):
    name = "dmoz_spider"
    allow_domains = ['readnovel.com']
    start_urls = [
        "https://www.readnovel.com/",
    ]

    def parse(self, response):
        cate_list = response.xpath('//*[@id="j-focus-slider"]/div/a')

        for cate in cate_list:
            book_link = cate.xpath('@href').extract()[0].replace('//', '')

            yield Request(url='https://' + book_link, callback=self.parse_book_detail)

    def parse_book_detail(self, response):
        # 'www.readnovel.com/book/7661570504015903'
        item = BookItem()
        # 小说链接
        item['book_url'] = response.url
        # 小说作者
        item['author_name'] = response.xpath('/html/body/div[1]/div[3]/div[1]/div[2]/h1/a/text()').extract()[0]
        # 小说名称
        item['name'] = response.xpath('/html/body/div[1]/div[3]/div[1]/div[2]/h1/em/text()').extract()[0]
        # 小说简介
        book_description = response.xpath('/html/body/div[1]/div[3]/div[1]/div[2]/p[3]').extract()[0]
        item['description'] = book_description
        # 小说封面图
        item['cover'] = response.xpath('//*[@id="bookImg"]/img/@src').extract()[0]
        # 小说字数
        item['word_count'] = response.xpath('/html/body/div[1]/div[3]/div[1]/div[2]/p[2]/span/text()').extract()[0]
        # 小说最后章节
        item['latest_chapter_id'] = 0

        yield item

        chapter_list = response.xpath('//*[@id="j-catalogWrap"]/div[2]/div[1]/ul/li')

        for chapter in chapter_list:
            item = BookChapterItem()

            item['book_url'] = response.url

            # 章节标题
            item['name'] = chapter.xpath('a/text()').extract()[0]
            # 章节字数统计
            chapter_word_count = re.search(r'章节字数：(.*)', chapter.xpath('a/@title').extract()[0], flags=0)
            item['word_count'] = chapter_word_count.group(1) if chapter_word_count else 0

            chapter_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

            # 章节入库时间
            item['created_at'] = chapter_time
            # 章节更新时间
            item['updated_at'] = chapter_time
            # 章节mongo_id
            item['db_id'] = 0
            # 小说章节id
            item['book_id'] = 0

            chapter_url = chapter.xpath('a/@href').extract()[0]

            # yield item
            # print(chapter_url)
            yield Request(url='https:' + chapter_url, meta={'item': item}, callback=self.parse_book_chapter_detail)

    # def parse_book_chapter_list(self, response):
    #     # 'www.readnovel.com/book/7661570504015903#Catalog'
    #     chapter_list = response.xpath('//*[@id="j-catalogWrap"]/div[2]/div[1]/ul/li')
    #
    #     for chapter in chapter_list:
    #         item = BookChapterItem()
    #
    #         # 章节标题
    #         item['name'] = chapter.xpath('a/@text()').extract()[0]
    #         # 章节字数统计
    #         chapter_word_count = re.search(r'章节字数：(.*)', chapter.xpath('a/@title').extract()[0], flags=0)
    #         item['word_count'] = chapter_word_count.group(1) if chapter_word_count else 0
    #         # 章节入库时间
    #         item['created_at'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
    #         # 章节更新时间
    #         item['updated_at'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
    #         # 章节mongo_id
    #         item['db_id'] = 0
    #         # 小说章节id
    #         item['book_id'] = 0
    #
    #         chapter_url = chapter.xpath('a/@href').extract()[0]
    #
    #         # yield item
    #         print(chapter_url)
    #         yield Request(url='https:' + chapter_url, meta={'item': item}, callback=self.parse_book_chapter_detail)

    def parse_book_chapter_detail(self, response):
        # item = BookChapterContentItem()
        item = response.meta['item']

        item['content'] = response.xpath('//*[@id="j_chapterBox"]/div/div/div[2]').extract()[0]

        yield item